# Real-Time Human Emotion Recognition from Facial Expressions using Deep Learning
# Overview
This deep learning project aims to recognize human emotions from facial expressions in real-time. Utilizing Convolutional Neural Networks (CNNs), Vision Transformers (ViT), and custom MobileNet model enhanced with patch extraction and attention mechanisms, the system is adept at classifying a wide range of emotions. This system is crucial for applications in human-computer interaction, mental health assessment, and interactive media.

# Dataset
Utilized three datasets: FER2013, RAF, and Affectnet.

FER2013: Grayscale images in 48x48 resolution across seven emotion classes.
https://www.kaggle.com/datasets/msambare/fer2013

RAF: RGB images in 100x100 resolution, encompassing the same emotion range.
http://www.whdeng.cn/raf/model1.html

Affectnet: High-resolution RGB images, adding an eighth emotion class 'contempt.'
http://mohammadmahoor.com/affectnet/

# Methodology
Employed various model architectures for emotion classification.

Real-time emotion recognition from video sequences using face detection and emotion classification techniques.

Comparative performance analysis of different models before and after data augmentation.

# Results
Demonstrated effectiveness of various models in recognizing emotions.

Custom MobileNet model exhibited strong performance with patch extraction and attention techniques.

Real-time system effectively classified emotional states from live video streams.
