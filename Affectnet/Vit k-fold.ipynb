{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4653fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from vit_keras import vit\n",
    "\n",
    "# Define the image size\n",
    "image_size = 224\n",
    "\n",
    "# Define the number of classes\n",
    "num_classes = 7\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 5\n",
    "\n",
    "# Create K-Fold cross-validator\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Define an array to store test accuracies for each fold\n",
    "test_accuracies = []\n",
    "\n",
    "# Perform cross-validation\n",
    "fold = 1\n",
    "for train_index, val_index in kf.split(train_generator.filenames):\n",
    "    print(f\"Fold: {fold}\")\n",
    "\n",
    "    # Create the ViTb16 model for this fold\n",
    "    vit_model = vit.vit_b16(\n",
    "        image_size=image_size,\n",
    "        activation='sigmoid',\n",
    "        pretrained=True,\n",
    "        pretrained_top=False,\n",
    "        include_top=False,\n",
    "        classes=num_classes\n",
    "    )\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(image_size, image_size, 3)),\n",
    "        vit_model,\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(11, activation=tfa.activations.gelu),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ],\n",
    "        name='vision_transformer'\n",
    "    )\n",
    "\n",
    "    # Compile the model\n",
    "    learning_rate = 1e-4\n",
    "    optimizer = tfa.optimizers.RectifiedAdam(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.2),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # Print the summary of the model for this fold\n",
    "    model.summary()\n",
    "\n",
    "    # Define a callback to save the best model based on validation accuracy for this fold\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=f\"best_model_vitb16_fold{fold}.h5\",\n",
    "        monitor=\"val_accuracy\",\n",
    "        verbose=1,\n",
    "        save_best_only=True,\n",
    "        mode=\"max\"\n",
    "    )\n",
    "\n",
    "    # Define early stopping based on validation accuracy\n",
    "    earlystopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        min_delta=1e-4,\n",
    "        patience=5,\n",
    "        mode='max',\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Train the model for this fold\n",
    "    epochs = 30\n",
    "    train_data_gen, val_data_gen = None, None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch: {epoch + 1}\")\n",
    "\n",
    "        # Initialize training and validation data generators for this epoch\n",
    "        if train_data_gen is None:\n",
    "            train_data_gen = train_generator\n",
    "        else:\n",
    "            train_data_gen.reset()\n",
    "        \n",
    "        if val_data_gen is None:\n",
    "            val_data_gen = validation_generator\n",
    "        else:\n",
    "            val_data_gen.reset()\n",
    "\n",
    "        # Train the model for this epoch using the current data generator\n",
    "        model.fit(\n",
    "            train_data_gen,\n",
    "            epochs=1,\n",
    "            validation_data=val_data_gen,\n",
    "            callbacks=[checkpoint, earlystopping]\n",
    "        )\n",
    "\n",
    "    # Load the best saved model for this fold\n",
    "    model.load_weights(f\"best_model_vitb16_fold{fold}.h5\")\n",
    "\n",
    "    # Evaluate the model on the test set for this fold\n",
    "    test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "    print(f\"Test Accuracy (Fold {fold}):\", test_accuracy)\n",
    "\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    fold += 1\n",
    "\n",
    "# Calculate and print the average accuracy\n",
    "average_accuracy = np.mean(test_accuracies)\n",
    "print(\"Average Test Accuracy:\", average_accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
